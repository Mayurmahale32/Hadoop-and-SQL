sudo apt update

sudo apt install openjdk-8-jdk -y

wget https://archive.apache.org/dist/hadoop/common/hadoop-2.7.5/hadoop-2.7.5.tar.gz 

sudo tar zxf hadoop-2.7.5.tar.gz

sudo mv hadoop-2.7.5 /usr/local/hadoop

cat >>$HOME/.bashrc <<EOL
# -- HADOOP ENVIRONMENT VARIABLES START -- #
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_HOME=/usr/local/hadoop
export PATH=\$PATH:\$HADOOP_HOME/bin
export PATH=\$PATH:\$HADOOP_HOME/sbin
export PATH=\$PATH:/usr/local/hadoop/bin/
export HADOOP_MAPRED_HOME=\$HADOOP_HOME
export HADOOP_COMMON_HOME=\$HADOOP_HOME
export HADOOP_HDFS_HOME=\$HADOOP_HOME
export YARN_HOME=\$HADOOP_HOME
export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
export PDSH_RCMD_TYPE=ssh
# -- HADOOP ENVIRONMENT VARIABLES END -- #
EOL

bash

sudo chown -R ubuntu:ubuntu /usr/local/hadoop

sudo su -c 'echo export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh'

sudo su -c 'echo export HADOOP_LOG_DIR=/var/log/hadoop/ >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh'

 sudo mkdir /var/log/hadoop/

sudo chown ubuntu:ubuntu -R /var/log/hadoop

touch /home/ubuntu/.ssh/config; echo -e \ "Host *\n StrictHostKeyChecking no\n  UserKnownHostsFile=/dev/null" \ > ~/.ssh/config


echo -e  'y\n'| ssh-keygen -t rsa -P "" -f $HOME/.ssh/id_rsa

cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys

sudo service ssh restart

ssh localhost

sudo sed -i '/<configuration>/,/<\/configuration>/d' /usr/local/hadoop/etc/hadoop/core-site.xml

sudo su -c 'cat >> /usr/local/hadoop/etc/hadoop/core-site.xml <<EOL
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost:9000</value>
  </property>
</configuration>
EOL'

mkdir -p /usr/local/hadoop/data/hdfs/namenode

sudo sed -i '/<configuration>/,/<\/configuration>/d' /usr/local/hadoop/etc/hadoop/hdfs-site.xml

sudo su -c 'cat >>/usr/local/hadoop/etc/hadoop/hdfs-site.xml <<EOL
<configuration>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///usr/local/hadoop/data/hdfs/namenode</value>
  </property>
<property>
   <name>dfs.secondary.http.address</name>
   <value>localhost:50090</value>
   <description>SecondaryNameNodeHostname</description>
</property>
 <property>
    <name>dfs.datanode.name.dir</name>
    <value>file:///usr/local/hadoop/data/hdfs/datanode</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>3</value>
  </property>
</configuration>
EOL'

mkdir -p /usr/local/hadoop/data/hdfs/datanode

sudo sed -i '/<configuration>/,/<\/configuration>/d' /usr/local/hadoop/etc/hadoop/yarn-site.xml

sudo su -c 'cat >>/usr/local/hadoop/etc/hadoop/yarn-site.xml <<EOL
<configuration><!-- Site specific YARN configuration properties -->
 <property>
     <name>yarn.nodemanager.aux-services</name>
     <value>mapreduce_shuffle</value>
   </property> 
   <property>
     <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
     <value>org.apache.hadoop.mapred.ShuffleHandler</value>
   </property>
   <property>
     <name>yarn.resourcemanager.hostname</name>
     <value>localhost</value>
   </property>
</configuration>
EOL'


cp  /usr/local/hadoop/etc/hadoop/mapred-site.xml.template /usr/local/hadoop/etc/hadoop/mapred-site.xml

 sudo sed -i '/<configuration>/,/<\/configuration>/d' /usr/local/hadoop/etc/hadoop/mapred-site.xml

sudo su -c 'cat >>/usr/local/hadoop/etc/hadoop/mapred-site.xml <<EOL
<configuration>
  <property>
    <name>mapreduce.jobtracker.address</name>
    <value>rm:54311</value>
  </property>
  <property>
    <name>mapreduce.framework.name</name>
    <value>localhost</value>
  </property>
</configuration>
EOL'

 sudo chown -R ubuntu:ubuntu $HADOOP_HOME

 hdfs namenode -format

start-all.sh

jps



